[#background,reftext="Background"]
== Background

This chapter provides information common to all CMO extensions.

=== Memory and Caches

A _memory location_ is a physical resource in a system uniquely identified by a
_physical address_. The _observers_ of a given memory location consist of the
bus initiators that can access that memory location. A given observer may not
be able to access all memory locations in a system, and two different observers
may or may not be able to observe the same set of memory locations.

In this specification, a _load operation_ (or _store operation_) is performed by
an observer to consume (or modify) the data at a given memory location. Load or
store operations may be performed as a result of explicit or implicit memory
accesses. Additionally, a _read operation_ (or _write operation_) is an
operation performed on the memory location to fetch (or update) the data at the
physical resource.

****

_Load and store operations are decoupled from read and write operations by
caches, described below. For example, a load operation may be satisfied by a
cache without performing a read operation in memory, or a store operation may be
satisfied by a cache that first performs a read operation._

****

A _cache_ is a structure that buffers copies of data to reduce average memory
latency. Any number of caches may be interspersed between an observer and a
memory location, and load and store operations from an observer may be satisfied
by a cache instead of the memory location.

Caches organize copies of data into _cache blocks_, each of which represents a
contiguous, naturally aligned power-of-two (or _NAPOT_) range of memory
locations. A cache block is identified by a physical address corresponding to
the underlying memory locations, and a _cache block operation_ (or _CBO_)
operates on one or more cache blocks.

****

_The Zicbom, Zicboz, and Zicbop extensions define operations on a single cache
block only._

****

Like an operation on a memory location, a read operation may be performed on a
cache to fetch a copy of a cache block, and a write operation may be performed
on a cache to update a copy of a cache block. In effect, read and write
operations transfer copies of cache blocks among caches and memory.

The capacity and organization of a cache and the size of a cache block are both
_implementation-defined_, and the execution environment provides software a
means to discover information about the caches and cache blocks in a system. For
the initial base set of CBOs, the size of a cache block shall be uniform
throughout the system.

****

_In future CMO extensions, the requirement for a uniform cache block size may be
relaxed._

****

=== Coherent Observers

For a given memory location, a _set of coherent observers_ consists of the set
of observers for which all of the following hold without software intervention:

* Store operations from all observers in the set appear to be serialized with
  respect to each other
* Store operations from all observers in the set eventually appear to all other
  observers in the set
* A load operation from an observer in the set returns data from a store
  operation from an observer in the set (or from the initial data in memory)

The coherent observers within such a set shall access a given memory location
with the same physical address and the same physical memory attributes; however,
if the coherence PMA for a given observer indicates a given memory location is
not coherent, that observer shall not be a member of a set of coherent observers
with any other observer for that memory location.

An observer who is a member of a set of coherent observers is said to be
_coherent_ with respect to the other observers in the set. On the other hand, an
observer who is _not_ a member is said to be _non-coherent_ with respect to the
observers in the set.

Caches introduce multiple copies of a given cache block, and the copies accessed
by the coherent observers are kept coherent by an _implementation-defined_
mechanism. A _coherent cache_ may allocate a copy of the cache block at any
time, obtaining a copy from another coherent cache or from the underlying memory
locations by performing a read operation. Similarly, a coherent cache may
deallocate a copy of the cache block at any time, transferring a copy to another
coherent cache by performing a write operation. Additionally, a coherent cache
may transfer a copy of the cache block to the underlying memory locations at any
time by performing a write operation, provided that a coherent observer
performed a store operation to the cache block since the previous write
operation to the memory locations. In the absence of an invalidate operation
performed by a coherent observer (see <<#Zicbom>>), at least one coherent cache
shall write the cache block to the underlying memory locations if a coherent
observer performed a store operation to the cache block; otherwise, no coherent
cache may perform a write operation of the cache block to the underlying memory
locations.

****

_The above restrictions ensure that a "clean" copy will not be written back into
memory._

****

=== Memory Ordering

==== Preserved Program Order

The preserved program order (abbreviated _PPO_) rules are defined by the RVWMO
memory ordering model. How the operations resulting from CMO instructions fit
into these rules is described below.

For cache block management instructions, the resulting invalidate, clean, and
flush operations behave as stores in the PPO rules subject to one additional
overlapping address rule. Specifically, if _a_ precedes _b_ in program order,
then _a_ will precede _b_ in the global memory order if:

* _a_ is an invalidate, clean, or flush, _b_ is a load, and _a_ and _b_ access
  overlapping memory addresses

****

_The above rule ensures that a subsequent load in program order never appears
in the global memory order before a preceding invalidate, clean, or flush
operation to an overlapping address._

****

Additionally, invalidate, clean, and flush operations are classified as W or O
(depending on the physical memory attributes for the corresponding physical
addresses) for the purposes of predecessor and successor sets in `FENCE`
instructions.

For cache block zero instructions, the resulting store operations simply 
behave as stores in the PPO rules.

Finally, as cache block prefetch instructions do not modify architectural memory
state, the resulting operations are _not_ ordered by the PPO rules.

==== Load Values

An invalidate operation may change the set of values that can be returned by a
load. In particular, an additional condition is added to the Load Value Axiom:

* If an invalidate operation _i_ precedes a load _r_ and operates on a byte _x_
  returned by _r_, and no store to _x_ appears between _i_ and _r_ in program
  order or in the global memory order, then _r_ returns any of the following
  values for _x_:

. If no clean or flush operations on _x_ precede _i_ in the global memory order,
  either the initial value of _x_ or the value of any store to _x_ that precedes
  _i_

. If no store to _x_ precedes a clean or flush operation on _x_ in the global
  memory order and if the clean or flush operation on _x_ precedes _i_ in the
  global memory order, either the initial value of _x_ or the value of any store
  to _x_ that precedes _i_

. If a store to _x_ precedes a clean or flush operation on _x_ in the global
  memory order and if the clean or flush operation on _x_ precedes _i_ in the
  global memory order, either the value of the latest store to _x_ that precedes
  the latest clean or flush operation on _x_ or the value of any store to _x_
  that both precedes _i_ and succeeds the latest clean or flush operation on _x_
  that precedes _i_ 

. The value of any store to _x_ by a non-coherent observer regardless of the
  above conditions

****

_The first three bullets describe the possible load values at different points
in the global memory order relative to clean or flush operations. The final
bullet implies that the load value may be produced by a non-coherent observer at
any time._

****

=== Instruction Execution and Traps

Similar to load and store instructions, CMO instructions are memory access
instructions that compute an effective address. The effective address is
ultimately translated into a physical address based on the privilege mode and
enabled translation mechanisms.

Execution of certain CMO instructions may result in traps due to CSR state,
described in the <<#csr_state>> section, or due to the various memory
translation and protection mechanisms. The trapping behavior of CMO instructions
is described in the following sections.

==== Illegal Instruction and Virtual Instruction Exceptions

Cache block management instructions and cache block zero instructions may take
an illegal instruction exception depending on the _current privilege mode_ and
the state of the CMO control registers described in the <<#csr_state>> section.
The current privilege mode refers to the privilege mode of the hart at the time
the instruction is executed.

Cache block prefetch instructions do _not_ take illegal instruction exceptions.

Additionally, CMO instructions do _not_ take virtual instruction exceptions.

==== Page Fault and Guest-Page Fault Exceptions

During address translation, CMO instructions may take a page fault depending on
the type of instruction, the _effective privilege mode_ (as determined by the
`MPRV`, `MPV`, and `MPP` bits in `mstatus`) of the resulting access, and the
permissions granted by the page table entry (PTE). If two-stage address
translation is enabled, CMO instructions may also take a guest-page fault.

A cache block management instruction requires read (`R=1`), write (`W=1`), or
execute (`X=1`) permission (given a legal PTE encoding for the `XWR` bits, as
specified by the privileged architecture) and, if applicable, user access
(`U=1`) in the effective privilege mode; otherwise, the instruction takes a
store page fault exception.

A cache block zero instruction requires write (`W=1`) permission (given a legal
PTE encoding for the `XWR` bits, as specified by the privileged architecture)
and, if applicable, user access (`U=1`) in the effective privilege mode;
otherwise, the instruction takes a store page fault exception.

If G-stage address translation is enabled, the above instructions take a 
store guest-page fault if the G-stage PTE does _not_ permit the access.

A cache block prefetch instruction requires read (`R=1`), write (`W=1`), or
execute (`X=1`) permission (given a legal PTE encoding for the `XWR` bits, as
specified by the privileged architecture) and, if applicable, user access
(`U=1`) in the effective privilege mode. In addition, an implementation may
require any of the following to perform a memory access:

* `PREFETCH.R` may require read (`R=1`) permission
* `PREFETCH.W` may require write (`W=1`) permission
* `PREFETCH.I` may require execute (`X=1`) permission

If the required permission is _not_ granted, however, the instruction does _not_
take a page fault or guest-page fault exception and retires without performing a
memory access.

===== Effect of other `xstatus` bits

The `mstatus.MXR` bit (also `sstatus.MXR`) and the `vsstatus.MXR` bit do _not_
affect the execution of CMO instructions.

The `mstatus.SUM` bit (also `sstatus.SUM`) and the `vsstatus.SUM` bit do _not_
affect the execution of CMO instructions beyond modifying permissions for
S/HS-mode and VS-mode accesses as specified by the privileged architecture.

==== Access Fault Exception

A CMO instruction may take an access fault exception, as detailed in the
privileged architecture specification, that interrupts the address translation
process. Assuming the address translation process completes with a valid
translation, a CMO instruction may also take an access fault exception depending
on the type of instruction, the effective privilege mode of the resulting
access, and the permissions granted by the physical memory protection (PMP) unit
and the physical memory attributes (PMAs).

****

_For now, we assume two things about PMAs:_

. _PMAs are the same for all physical addresses in a cache block_
. _Memory that can be cached cannot be write-only_

****

Read (`R`), write (`W`), and execute (`X`) permissions are granted by the PMP
and the PMAs. Although the PMP may grant different permissions to different
physical addresses in a cache block, the PMAs for a cache block shall be the
same for _all_ physical addresses in the cache block and read permission shall
be granted if write permission has been granted. If these PMA constraints are
_not_ met, the behavior of a CMO instruction is UNSPECIFIED.

For the purposes of access fault determination, the following terms are defined
for a given physical address:

* _joint read permission_ is granted when both the PMP and PMAs allow read
  access to the physical address
* _joint write permission_ is granted when both the PMP and PMAs allow write
  access to the physical address
* _joint execute permission_ is granted when both the PMP and PMAs allow execute
  access to the physical address

A cache block management instruction requires joint read, joint write, or joint
execute permission (given legal PMA and PMP encodings for the `XWR` bits, as
specified by the privileged architecture) for each physical address in a cache
block; otherwise, the instruction takes a store access fault exception.

A cache block zero instruction requires joint write permission (given legal PMA
and PMP encodings for the `XWR` bits, as specified by the privileged
architecture) for each physical address in a cache block; otherwise, the
instruction takes a store access fault exception.

A cache block prefetch instruction requires joint read, joint write, or joint
execute permission (given legal PMA and PMP encodings for the `XWR` bits, as
specified by the privileged architecture) for each physical address in a cache
block. In addition, an implementation may require any of the following to
perform a memory access:

* `PREFETCH.R` may require joint read permission
* `PREFETCH.W` may require joint write permission
* `PREFETCH.I` may require joint execute permission

If the required permission is _not_ granted, however, the instruction does _not_
take an access fault exception and retires without performing a memory access.

==== Address Misaligned Exception

CMO instructions do _not_ generate address misaligned exceptions.

==== Breakpoint Exception and Debug Mode Entry

Unless otherwise defined by the debug architecture specification, the behavior
of trigger modules with respect to CMO instructions is UNSPECIFIED.

****

_For the Zicbom, Zicboz, and Zicbop extensions, this specification recommends
the following common trigger module behaviors:_

* Type 6 address match triggers, i.e. `tdata1.type=6` and `mcontrol6.select=0`,
  should be supported

* Type 2 address/data match triggers, i.e. `tdata1.type=2`, should be
  unsupported
    
* The size of a memory access equals the size of the cache block accessed, and
  the compare values follow from the addresses of the NAPOT memory region
  corresponding to the cache block containing the effective address
  
* Unless an encoding for a cache block is added to the `mcontrol6.size` field,
  an address trigger should only match a memory access from a CBO instruction if
  `mcontrol6.size=0`
    
_If the Zicbom extension is implemented, this specification recommends the
following additional trigger module behaviors:_

* Implementing address match triggers should be optional

* Type 6 data match triggers, i.e. `tdata1.type=6` and `mcontrol6.select=1`,
  should be unsupported

* Memory accesses are considered to be stores, i.e. an address trigger matches
  only if `mcontrol6.store=1`

_If the Zicboz extension is implemented, this specification recommends the
following additional trigger module behaviors:_

* Implementing address match triggers should be mandatory

* Type 6 data match triggers, i.e. `tdata1.type=6` and `mcontrol6.select=1`,
  should be supported, and implementing these triggers should be optional

* Memory accesses are considered to be stores, i.e. an address trigger matches
  only if `mcontrol6.store=1`

_If the Zicbop extension is implemented, this specification recommends the
following additional trigger module behaviors:_

* Implementing address match triggers should be optional

* Type 6 data match triggers, i.e. `tdata1.type=6` and `mcontrol6.select=1`,
  should be unsupported

* Memory accesses may be considered to be loads or stores depending on the
  implementation, i.e. whether an address trigger matches on these instructions
  when `mcontrol6.load=1` or `mcontrol6.store=1` is _implementation-defined_

_This specification also recommends that the behavior of trigger modules with
respect to the Zicboz extension should be defined in version 1.0 of the debug
architecture specification. The behavior of trigger modules with respect to the
Zicbom and Zicbop extensions is expected to be defined in future extensions._

****

=== Effects on Constrained LR/SC Loops

Executing any cache block management instruction (`CBO.INVAL`, `CBO.CLEAN`, or
`CBO.FLUSH`) or a cache block zero instruction (`CBO.ZERO`) may cause a
reservation on another hart to be lost. As a result, executing one of these
instructions constitutes an additional event (similar to executing an
unconditional store or an AMO instruction) that satisfies the eventuality
guarantee of constrained LR/SC loops defined in the A extension.

****

_Executing any cache block prefetch instruction (`PREFETCH.I`, `PREFETCH.R`, or
`PREFETCH.W`) does not impact the eventuality guarantee of constrained LR/SC
loops defined in the A extension; however, these instructions may cause the
periodic cancellation of a reservation on another hart._

****

=== Configuration

*TBD*

* general cache structure/organization?
* relationship among harts? (i.e. which set does a hart belong to?)
* cache block size for management and prefetch
* cache block size for zero
* CBIE support at each privilege level
* what happens if CBO operations are executed on addresses that are not cached?

At minimum, the configuration structure needs to describe the two cache block
sizes and the supported CBIE values.
